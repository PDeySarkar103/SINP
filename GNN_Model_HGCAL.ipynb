{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb91df1-77f1-4467-b043-d0b6cc7377e4",
   "metadata": {},
   "source": [
    "# Application of GCN on HGCAL data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71560501-5bd5-4d1d-a323-65a0c99869ec",
   "metadata": {},
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737133ca-4c6e-41c7-81e6-ab9aca2cd3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General packages\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Packages for GNN\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "#from torch_geometric.nn import GCNConv, global_add_pool\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec0310-8720-4d28-bdab-0adaa448d323",
   "metadata": {},
   "source": [
    "## ROOT ---> Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58912548-98a3-417f-bedc-dbff20f1fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=uproot.open(\"ntuple_pi+_100GeV_100keve.root:AllLayers\")\n",
    "branches=[\"hit_x\",\"hit_y\",\"hit_z\",\"hit_l\",\"hit_E\"]\n",
    "events=file.arrays(branches,library=\"ak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89261988-9c1e-4370-8eb8-ef5a7cbfef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events  ### Awkawrd array in Dictionary like format\n",
    "#type(events)\n",
    "#events.hit_x # Returns the awkard arrays for the hit_x for all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2801917d-21c9-4174-8d65-47c2ff60ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#events[0].hit_x # Returns the hit_x data for the first event, as numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e12a56-649b-415c-aba8-e38a372b4c8d",
   "metadata": {},
   "source": [
    "## Creating the event graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "010b5133-5827-4188-b005-8f614cc8485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(event,k=8):\n",
    "    x=ak.to_numpy(event.hit_x)\n",
    "    y=ak.to_numpy(event.hit_y)\n",
    "    z=ak.to_numpy(event.hit_z)\n",
    "    l=ak.to_numpy(event.hit_l)\n",
    "    E=ak.to_numpy(event.hit_E)\n",
    "    #Removing zero energy hits\n",
    "    mask_E=E>0\n",
    "    x,y,z,l,E=x[mask_E],y[mask_E],z[mask_E],l[mask_E],E[mask_E]\n",
    "    coords=np.column_stack((x,y,z))\n",
    "    N=len(coords)\n",
    "    if N<k+1:\n",
    "        return None\n",
    "    \n",
    "    #Node features\n",
    "    node_features=torch.from_numpy(np.column_stack((x,y,z,l,E))).float()\n",
    "\n",
    "    #Global KNN\n",
    "    knn=NearestNeighbors(n_neighbors=k+1,algorithm=\"kd_tree\").fit(coords)\n",
    "    knn_dist,knn_idx=knn.kneighbors(coords)\n",
    "    knn_idx=knn_idx[:,1:] #Removes the self hit\n",
    "    #print(knn_dist[9,:],knn_idx[9,:])\n",
    "\n",
    "    #Edge construction\n",
    "    src=np.repeat(np.arange(N),k)\n",
    "    dst=knn_idx.reshape(-1)\n",
    "    mask=dst>=0\n",
    "    src,dst=src[mask],dst[mask]\n",
    "    edge_index=torch.tensor(np.vstack([src,dst]),dtype=torch.long)\n",
    "\n",
    "    #Edge attributes\n",
    "    edge_attr = torch.tensor((E[src] * E[dst]).reshape(-1, 1),dtype=torch.float)\n",
    "\n",
    "    #Final creation\n",
    "    graph= Data(x=node_features,edge_index=edge_index,edge_attr=edge_attr)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba20d905-3d16-48fa-b34b-2df22443a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=[create_graph(event,k=8) for event in events]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951178ef-2765-4294-966b-6857af51e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf67de-9d0b-43a2-bea5-bc1107a2be1d",
   "metadata": {},
   "source": [
    "## Splitting into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9afd3505-d8ff-4b69-b200-8ce0ffb7af06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 70000\n",
      "Validation samples: 9000\n",
      "Test samples: 21000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#First split: Train vs Temp(Val+Test)\n",
    "train_data, temp_data= train_test_split(graph, test_size=0.3, random_state=42)\n",
    "\n",
    "#Second split: Test vs Val\n",
    "val_data, test_data= train_test_split(temp_data, test_size=0.7, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb0bb6-f8eb-460e-a5c8-152984544e99",
   "metadata": {},
   "source": [
    "## Using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e2cbca-e32a-4fe4-a46f-2e4c2930da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "batch_size=64\n",
    "\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader=DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6429c387-d722-4492-9e78-040854c386ef",
   "metadata": {},
   "source": [
    "## Making the GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674ec77-d500-426c-93a0-b1a415d3f057",
   "metadata": {},
   "source": [
    "### Developing the Message Passing Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dc5c1cf-89a3-4e80-8f69-56eca36e169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the message passing network\n",
    "import torch\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        #Here, in_channels: Input node features\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin=Linear(in_channels,out_channels,bias=False)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "        \n",
    "    def forward(self,x,edge_index):\n",
    "        # x has the shape [No. of hits, in_channels]\n",
    "        #edge_index has shape [2, No. of edges]\n",
    "        #Step-1: Add self loops\n",
    "        edge_index,_=add_self_loops(edge_index,num_nodes=x.size(0))\n",
    "        #Step-2: Linearly transform node feature matrix\n",
    "        x=self.lin(x)\n",
    "        #Step-3: Compute Normalization\n",
    "        row,col=edge_index\n",
    "        deg=degree(col,x.size(0))\n",
    "        deg_inv_sqr=deg.pow(-0.5)\n",
    "        deg_inv_sqr[deg_inv_sqr==float('inf')]=0\n",
    "        norm=deg_inv_sqr[row]*deg_inv_sqr[col]\n",
    "        #Step-4-5: Propagating the message- Normalize the node features and then add\n",
    "        out=self.propagate(edge_index,x=x,norm=norm)\n",
    "        #Step 6: Apply the end bias vector\n",
    "        out=out+self.bias\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1,1)*x_j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a6aa4-bdd6-4847-8a9d-c3e9a96e30a2",
   "metadata": {},
   "source": [
    "### Stacking the GNN layers for 'Convolution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4d161e8-5ac1-4505-ad55-d6342fb73c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv,global_mean_pool\n",
    "\n",
    "class GCN_Event_Classifier(nn.Module):\n",
    "    def __init__(self, input_dim,hidden_dim,output_dim):\n",
    "        super().__init__()\n",
    "        #The GCN Layers\n",
    "        self.conv1=GCNConv(input_dim,hidden_dim)\n",
    "        self.conv2=GCNConv(hidden_dim,hidden_dim)\n",
    "        self.conv3=GCNConv(hidden_dim,hidden_dim)\n",
    "        #Regularization\n",
    "        self.dropout=nn.Dropout(p=0.1)\n",
    "        #Output- MLP- mainly doing the classification task.\n",
    "        self.output=nn.Sequential(\n",
    "            nn.Linear(hidden_dim,hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self,data):\n",
    "        #x,edge_index=data.x, data.edge_index\n",
    "        x,edge_index,batch=data.x,data.edge_index,data.batch\n",
    "        #First GCN Block\n",
    "        x=self.conv1(x,edge_index)\n",
    "        x=F.ReLU(x)\n",
    "        x=self.dropout(x)\n",
    "        #Second GCN block\n",
    "        x=self.conv2(x,edge_index)\n",
    "        x=F.ReLU(x)\n",
    "        x=self.dropout(x)\n",
    "        #Third GCN block\n",
    "        x=self.conv3(x,edge_index)\n",
    "        x=F.ReLU(x)\n",
    "        x=self.dropout(x)\n",
    "        \n",
    "        #Saving the node embeddings\n",
    "        node_embedding=x\n",
    "        \n",
    "        #Global pooling\n",
    "        event_embedding=global_mean_pool(x,batch)\n",
    "        #Node-level-predictions\n",
    "        out=self.output(event_embedding)\n",
    "        \n",
    "        return out,node_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1fdd241-4d6c-4403-9059-0b72d11ae749",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6c9e1d6-0f07-49fb-aeb8-2869c32c8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GCN_Event_Classifier(input_dim=5,hidden_dim=64,output_dim=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49240b79-7eaa-45f5-b912-08a28c6d11bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN_Event_Classifier(\n",
       "  (conv1): GCNConv(5, 64)\n",
       "  (conv2): GCNConv(64, 64)\n",
       "  (conv3): GCNConv(64, 64)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (output): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66811ba4-03a5-4c92-b9ee-955288472b48",
   "metadata": {},
   "source": [
    "### Developing the training, validation and testing loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55211511-6d13-4d58-b0b9-3ed6321f1f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "criterion=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc1f95-0256-4100-996d-520398f9017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    train_loss=0.0\n",
    "    for batch in train_loader:\n",
    "        batch=batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out,_=model(batch)\n",
    "        loss=criterion(out,batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss.item()\n",
    "        \n",
    "    return total_loss/len(train_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
